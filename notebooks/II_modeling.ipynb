{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB8BaFLiRfWC"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "<img width=25% src=\"https://raw.githubusercontent.com/gabrielcapela/credit_risk/main/images/myself.png\" align=right>\n",
        "\n",
        "# **Credit Risk Assessment Project**\n",
        "\n",
        "*by Gabriel Capela*\n",
        "\n",
        "[<img src=\"https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white\"/>](https://www.linkedin.com/in/gabrielcapela)\n",
        "[<img src=\"https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white\" />](https://medium.com/@gabrielcapela)\n",
        "\n",
        "---\n",
        "\n",
        "This project aims to develop a **Machine Learning model capable of predicting the probability of customer default** at the time of a credit card application, even before any payment history is available.\n",
        "\n",
        "Default prediction is critical to minimize financial losses, preserve institutional credibility, and provide fair and efficient access to credit. However, the task is challenging due to limited data at the application stage, potential classification errors (false positives/negatives), and the need for representative historical data.\n",
        "\n",
        "The ultimate goal is to provide financial institutions with a **data-driven decision-support tool** that improves the accuracy and fairness of credit approval processes.\n",
        "\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "<img width=90% src=\"https://raw.githubusercontent.com/gabrielcapela/credit_risk/main/images/crisp-dm.jpeg\">\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "This notebook will cover the **last three phases** of the project: Modeling, Evaluation and Deployment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka-oIr9ISBzC"
      },
      "source": [
        "#  Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qj_lPa2vfzv"
      },
      "source": [
        "This step will follow the following sequence: First, we will **create a pipeline** for training multiple models, after which **two models will be chosen** to move forward. These two models will be **hyperparameterized** and, finally, they will perharps be combined into a **ensemble model**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The X_train shape is 26754 x 82\n",
            "The X_test shape is 11466 x 82\n",
            "The y_train shape is 26754 x 1\n",
            "The y_test shape is 11466 x 1\n"
          ]
        }
      ],
      "source": [
        "# Importing the data\n",
        "import pandas as pd\n",
        "X_train= pd.read_csv(\"../data/X_train.csv\")\n",
        "X_test= pd.read_csv(\"../data/X_test.csv\")\n",
        "y_train= pd.read_csv(\"../data/y_train.csv\")\n",
        "y_test= pd.read_csv(\"../data/y_test.csv\")\n",
        "\n",
        "print(f'The X_train shape is {X_train.shape[0]} x {X_train.shape[1]}')\n",
        "print(f'The X_test shape is {X_test.shape[0]} x {X_test.shape[1]}')\n",
        "print(f'The y_train shape is {y_train.shape[0]} x {y_train.shape[1]}')\n",
        "print(f'The y_test shape is {y_test.shape[0]} x {y_test.shape[1]}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PgE07I2DTVy"
      },
      "source": [
        "##Creating a Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zACpH9NJ1XJP"
      },
      "source": [
        "A Pipeline will be created to chain the cross validation and data standardization process, in order to organize this flow and allow the simultaneous testing of several different models, avoiding code repetition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u7Jr-GVW8k6i",
        "outputId": "ee36f9f9-ec11-4a37-8522-65057d366b04"
      },
      "outputs": [],
      "source": [
        "#Importing the necessary packages and models\n",
        "from sklearn.pipeline import Pipeline\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from sklearn.metrics import recall_score, precision_score, accuracy_score, confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#Highlighting quantitative variables so that only they are standardized in pre-processing\n",
        "num_features = ['account_length', 'number_vmail_messages', 'total_day_minutes',\n",
        "                'total_day_calls', 'total_day_charge', 'total_eve_minutes',\n",
        "                'total_eve_calls', 'total_eve_charge', 'total_night_minutes',\n",
        "                'total_night_calls', 'total_night_charge', 'total_intl_minutes',\n",
        "                'total_intl_calls', 'total_intl_charge', 'customer_service_calls']\n",
        "\n",
        "cat_features = ['international_plan', 'voice_mail_plan', '408', '415', '510']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num_scaler', StandardScaler(), num_features),\n",
        "    ('passthrough', 'passthrough', cat_features)\n",
        "])\n",
        "\n",
        "#List of models\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'SVM': SVC(probability=True),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'KNN': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "#Defining the number of folds for Cross-Validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "#List to store the results\n",
        "results = []\n",
        "\n",
        "#Testing all models\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTesting {name}...\")\n",
        "\n",
        "    #Creating the pipeline\n",
        "    pipeline = ImbPipeline([\n",
        "        ('preprocessing', preprocessor),\n",
        "        ('smote', SMOTE(sampling_strategy='auto', random_state=42)),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    #Getting Predictions with Cross-Validation\n",
        "    y_pred = cross_val_predict(pipeline, X_train, y_train, cv=cv)\n",
        "\n",
        "    #Calculating metrics\n",
        "    recall = recall_score(y_train, y_pred)\n",
        "    precision = precision_score(y_train, y_pred)\n",
        "    accuracy = accuracy_score(y_train, y_pred)\n",
        "\n",
        "    results.append([name, recall, precision, accuracy])\n",
        "\n",
        "    #Creating classification Report and confusion matrix\n",
        "    print(\"Classification Report:\\n\", classification_report(y_train, y_pred, digits=4))\n",
        "    cm = confusion_matrix(y_train, y_pred)\n",
        "\n",
        "    #Plotting the confusion matrix\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "    plt.title(f'Confusion Matrix - {name}')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.show()\n",
        "    print('\\n\\n')\n",
        "\n",
        "#Creating a dataframe with the results\n",
        "df_results = pd.DataFrame(results, columns=['Model', 'Recall', 'Precision', 'Accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ-68ufdDFVV"
      },
      "source": [
        "## Choosing the best Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaYpAsS8F4ar"
      },
      "source": [
        "In churn analysis, our main goal is to **correctly identify customers who will cancel**, as this allows the company to take preventive actions to retain them. For this reason, **Recall will be our main metric**, as it measures the proportion of customers who actually canceled and who were correctly classified by the model.\n",
        "\n",
        "However, **we will also evaluate Precision** in the background, as it helps us ensure that, when predicting churn, **we are minimizing false positives, avoiding unnecessary alarms**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "kI8FghZp9r7W",
        "outputId": "6c61682b-37d2-40e6-eb94-febe88f92504"
      },
      "outputs": [],
      "source": [
        "#Displaying the table with the main metrics\n",
        "print(\"\\nðŸ“Š Model Performance Summary:\")\n",
        "df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OArXIKhdHBsd"
      },
      "source": [
        "The goal is to **choose 2 models**. Random Forest, Logistic regression and Decision tree had the best recall rate, but the Logistic regression model had a lower precision rate. Therefore, **Random Forest and Decision tree will be chosen for the next stage**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVGQl8HRiRPE"
      },
      "source": [
        "##Hyperparameters Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENxuECK4Kutn"
      },
      "source": [
        "Hyperparameter tuning is **select the best combination of hyperparameters** (e.g., number of estimators, learning rate, or tree depth) that allow the model to generalize well to unseen data, **maximizing its predictive accuracy while minimizing overfitting**.\n",
        "\n",
        "\n",
        "To this **RandomizedSearchCV will be used**. It randomly samples from the specified hyperparameter space for a given number of iterations and evaluates each combination using cross-validation. RandomizedSearch helps to identify the best performing hyperparameters for the model, balancing accuracy and computational efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "f8gldEJjNscQ",
        "outputId": "49a04ecd-2fbb-4e24-e7e8-060e9a4cdad7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Model dictionary (Random Forest and Decision Tree)\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Hyperparameter grids for RandomizedSearchCV\n",
        "param_grid_rf = {\n",
        "    'classifier__n_estimators': [100, 200, 300],\n",
        "    'classifier__max_depth': [10, 20, 30],\n",
        "    'classifier__min_samples_split': [2, 5, 10],\n",
        "    'classifier__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "param_grid_dt = {\n",
        "    'classifier__max_depth': [5, 10, 20],\n",
        "    'classifier__min_samples_split': [2, 5, 10],\n",
        "    'classifier__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Define cross-validation strategy\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an empty list to store metrics\n",
        "metrics = []\n",
        "\n",
        "# Loop through models and perform training/evaluation with and without hyperparameter tuning\n",
        "for name, model in models.items():\n",
        "    # Create pipeline without hyperparameter tuning\n",
        "    pipeline = ImbPipeline([\n",
        "        ('preprocessing', preprocessor),\n",
        "        ('smote', SMOTE(sampling_strategy='auto', random_state=42)),  # Oversampling within CV\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    # Evaluate without hyperparameter tuning\n",
        "    y_pred = cross_val_predict(pipeline, X_train, y_train, cv=cv)\n",
        "    recall = recall_score(y_train, y_pred)\n",
        "    precision = precision_score(y_train, y_pred)\n",
        "    accuracy = accuracy_score(y_train, y_pred)\n",
        "\n",
        "    metrics.append([name + ' (No Hyperparameter Tuning)', recall, precision, accuracy])\n",
        "\n",
        "    # Hyperparameter tuning with RandomizedSearchCV for Random Forest and Decision Tree\n",
        "    if name == 'Random Forest':\n",
        "        random_search_rf = RandomizedSearchCV(pipeline, param_distributions=param_grid_rf, n_iter=10, cv=cv, random_state=42, n_jobs=-1)\n",
        "        random_search_rf.fit(X_train, y_train)\n",
        "        best_model = random_search_rf.best_estimator_\n",
        "    elif name == 'Decision Tree':\n",
        "        random_search_dt = RandomizedSearchCV(pipeline, param_distributions=param_grid_dt, n_iter=10, cv=cv, random_state=42, n_jobs=-1)\n",
        "        random_search_dt.fit(X_train, y_train)\n",
        "        best_model = random_search_dt.best_estimator_\n",
        "\n",
        "    # Evaluate with hyperparameter tuning\n",
        "    y_pred_tuned = cross_val_predict(best_model, X_train, y_train, cv=cv)\n",
        "    recall_tuned = recall_score(y_train, y_pred_tuned)\n",
        "    precision_tuned = precision_score(y_train, y_pred_tuned)\n",
        "    accuracy_tuned = accuracy_score(y_train, y_pred_tuned)\n",
        "\n",
        "    metrics.append([name + ' (With Hyperparameter Tuning)', recall_tuned, precision_tuned, accuracy_tuned])\n",
        "\n",
        "# Create a DataFrame with the results\n",
        "metrics_df = pd.DataFrame(metrics, columns=['Model', 'Recall', 'Precision', 'Accuracy'])\n",
        "\n",
        "# Display the results as a table\n",
        "print(\"\\nðŸ“Š Performance summary of models with hyperparameterization:\")\n",
        "metrics_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otsi3PmoiWxx"
      },
      "source": [
        "##Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZsfsYEJs2cv"
      },
      "source": [
        "In this section, **the two models will be combined to improve the performance** of the final model.\n",
        "\n",
        "The **voting classifier** is an effective way to combine models, where each model contributes its prediction and the final decision is based on the majority or average of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "3fxF0jmFU302",
        "outputId": "a12b2ba3-752a-4866-8c77-0632c03c3caf"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "#Create a list of the tuned models\n",
        "models_tuned = {\n",
        "    'Random Forest (With Hyperparameter Tuning)': random_search_rf.best_estimator_,\n",
        "    'Decision Tree (With Hyperparameter Tuning)': random_search_dt.best_estimator_\n",
        "}\n",
        "\n",
        "#Create an ensemble model using VotingClassifier (soft voting)\n",
        "ensemble_model = VotingClassifier(estimators=[\n",
        "    ('random_forest', models_tuned['Random Forest (With Hyperparameter Tuning)']),\n",
        "    ('decision_tree', models_tuned['Decision Tree (With Hyperparameter Tuning)'])\n",
        "], voting='soft')\n",
        "\n",
        "#Evaluating the ensemble model\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "y_pred_ensemble = cross_val_predict(ensemble_model, X_train, y_train, cv=cv)\n",
        "recall_ensemble = recall_score(y_train, y_pred_ensemble)\n",
        "precision_ensemble = precision_score(y_train, y_pred_ensemble)\n",
        "accuracy_ensemble = accuracy_score(y_train, y_pred_ensemble)\n",
        "\n",
        "# Add the ensemble results to the metrics list\n",
        "metrics.append(['Ensemble (Random Forest + Decision Tree)', recall_ensemble, precision_ensemble, accuracy_ensemble])\n",
        "\n",
        "# Convert the metrics list to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics, columns=['Model', 'Recall', 'Precision', 'Accuracy'])\n",
        "\n",
        "# Display the results as a table\n",
        "print(\"\\nðŸ“Š Performance summary of models with hyperparameterization and with Ensemble:\")\n",
        "metrics_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWucJiQkYHXS"
      },
      "source": [
        "The **recall rate of the ensemble model was very close** to that of the Decision tree model with hyperparameters, which had the highest recall rate. In addition, the **ensemble model had higher precision and accuracy rates** than the Decision tree model with hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIxbYxctSDMQ"
      },
      "source": [
        "#Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UpW32K-6vtw"
      },
      "source": [
        "Now we will perform the **final evaluation of the ensemble model** using the **test data,** which were separated before modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "DCZPFNCEZDsV",
        "outputId": "057cd0ac-bc84-4dc7-efa5-c14054a52c5d"
      },
      "outputs": [],
      "source": [
        "#Evaluating the ensemble model on the test data\n",
        "y_pred_test = ensemble_model.predict(X_test)\n",
        "\n",
        "#Calculating metrics\n",
        "recall_test = recall_score(y_test, y_pred_test)\n",
        "precision_test = precision_score(y_test, y_pred_test)\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "#Generating a confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.title('Confusion Matrix - Ensemble Model')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n",
        "\n",
        "# Adding the new row with the ensemble model metrics with the teste data\n",
        "metrics.append(['Ensemble (TEST DATA)', recall_test, precision_test, accuracy_test])\n",
        "# Convert the metrics list to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics, columns=['Model', 'Recall', 'Precision', 'Accuracy'])\n",
        "\n",
        "# Display the results as a table\n",
        "print(\"\\nðŸ“Š Performance summary of models with hyperparameterization and with Ensemble:\")\n",
        "metrics_df = metrics_df.drop([0, 2]).reset_index(drop=True)\n",
        "metrics_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdt-9O9Ffeh9"
      },
      "source": [
        "Model evaluation shows **promising results**. After fine-tuning the hyperparameters of the Random Forest and Decision Tree models, their performance was further improved when combined into an ensemble. The final ensemble model demonstrated **strong recall (0.778)**, precision (0.717), and accuracy (0.922) on the test data, indicating its robustness in predicting churn. This performance suggests that the ensemble approach, leveraging the strengths of both models, **is effective for the task at hand and can be trusted for future predictions**.\n",
        "\n",
        "With these results, **the model is now ready for deployment.** By integrating it into an application, users will be able to input customer data and receive a churn probability score in real-time. This will enable businesses to proactively identify at-risk customers and implement targeted retention strategies. **The model's strong performance ensures that it can be a valuable tool for decision-making,** helping to minimize churn and improve customer satisfaction."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_credit_risk",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
